---
title: "Diversity analysis"
date: "`r Sys.time()`"
bibliography: mixed.bib
---

This is an attempt at a streamlined and yet complete, relatively *a priori*/non-
snooped model analysis. Some parts of the analysis have been moved into separate `.R` files: the overall workflow is

![](make.png)

```{r load_packages,message=FALSE}
library('lme4')        ## lmer etc.
stopifnot(packageVersion("lme4")>="1.1-14")
library('bbmle')       ## AICtab, cosmetic
library('broom')
library('lattice')
library('gridExtra')
library('ggplot2'); theme_set(theme_bw())
## library('ggalt')
library('dplyr')
library('tidyr')
library('tibble') ## rownames_to_column
## devtools::install_github("hohenstein/remef")
library('remef')
library('r2glmm')
library('pander')  ## for tables
```

```{r get_utils}
source("mmd_utils.R")
```

```{r knitr_setup,echo=FALSE}
library(knitr)
opts_chunk$set(error=FALSE)
```

```{r get_data,cache=TRUE}
L <- load("ecoreg2.RData")
```

Limit all observations with all predictor variables > 0 and no biome 98/99; set `biome` as factor. Log and scale/center variables as appropriate. This leaves us with `r ncol(ecoreg)` variables and
`r nrow(ecoreg)` observations.

## Model fitting

This can now be done semi-automatically (i.e., fit all combinations
of random effects) by using the function `fit_all` from the `mmd_utils.R`
file (sourced above), e.g. `fit_all(response="mbirds_log")`

However, the `mmd_fitbatch.R` code has already run all
random-effects model combinations for all four response variables,
so we can extract just one set of models (and profiles) this way:

```{r get_allfits}
L <- load("allfits.RData")
names(allfits)
focal <- "mamph_log"
results <- allfits[[focal]]
## profiles (from best model for each response variable/set of fits only)
L <- load("allprofs.RData")
names(profList) <- names(allfits)
pp <- profList[[focal]] 
```

```{r summarize_model}
subset(aa2 <- AICtabx(results),dAIC<10)
```

```{r get_best}
## get the name of the best model from all of the different RE models
best_names <- sapply(allfits,get_best_name)
## create a list of the best model for each taxon
best_models <- Map(function(x,n) x[[n]],
                   allfits,best_names)
## e.g. ecoreg$birdres <- residuals(best_models[["mbirds_log"] ])
best_df <- sapply(best_models, function(x) attr(logLik(x), "df"))
```

To get residuals use `residuals(best_model,re.form=NULL)`; this
uses all of the random effects.

Best non-singular models (by AIC):
```{r bestmodels,results="asis"}
pander(data.frame(taxon=names(allfits),best_model=best_names,
                  df=best_df),row.names=FALSE)
```

Diagnostics?

```{r diagplots}
best_model <- best_models[[focal]]
grid.arrange(plot(best_model,type=c("p","smooth")),
             lattice::qqmath(best_model),nrow=1)
```

```{r ranef_mod}
rr <- ranef(best_model)
```

The best arrangement of the random effect plots will vary somewhat
depending on which components have single vs multiple terms ... the
`biome_FR` plot will be tall in any case (because there are many levels),
but the widest plots will be those with `diag` or `full` specifications
rather than intercept-only models.

```{r ranefplots,fig.width=8}
ranefplots <- lattice::dotplot(rr)
do.call(grid.arrange,c(ranefplots[2:3],list(nrow=1)))
```

```{r ranefplot2,fig.width=10,fig.height=10}
reorder_var <- "NPP_cv_sc"
if (!is.null(reorder_var) && reorder_var %in% names(rr$biome_FR)) {
    ## only try to reorder if the variable is actually there ...
    rr$biome_FR <- rr$biome_FR[order(rr$biome_FR[[reorder_var]]),]
}
rr3 <- as.data.frame(rr$biome_FR) %>%
    rownames_to_column("br") %>%
    ## mutate(br=reorder(br,order(NPP_cv_ctr))) %>%
    gather(key=term,value=value,-br)
ggplot(rr3,aes(value,br))+facet_wrap(~term,nrow=1)+geom_point()+
    theme(panel.spacing=grid::unit(0,"lines"))+
    labs(x="",y="")
```

```{r varcorr}
VarCorr(best_model)
```

## coefficient plot of all models tried

```{r coefplot,echo=FALSE,fig.width=10,fig.height=8}
all_coef <- dplyr::bind_rows(lapply(results,tidy,effect="fixed"),.id="model")
all_coef <- merge(all_coef,data.frame(model=rownames(aa2),aa2))
all_coef$model <- gsub("diag","d",
                       gsub("full","f",
                            gsub("int","i",
                                 gsub("flor_realms","fr",
                                      gsub("biome","b",all_coef$model)))))
all_coef$model <- reorder(factor(all_coef$model),-all_coef$dAIC)
ggplot(all_coef,aes(estimate,model,colour=singular))+geom_point()+
    geom_errorbarh(aes(xmin=estimate-1.96*std.error,
                       xmax=estimate+1.96*std.error),height=0)+
    facet_wrap(~term,scale="free_x")+
    geom_vline(xintercept=0,lty=2)
```

```{r profplots,echo=FALSE,eval=FALSE}
xyplot(pp)
xyplot(logProf(pp))
## splom(pp) ## impressive but not very useful
```

Check difference between Wald and likelihood profile
confidence intervals.
In principle profile CIs are more accurate - **if** the computations
have run reliably ... but I would probably be conservative and take
the wider of the two.

**FIXME**: Wald CIs only give fixed-effect confidence intervals.
Could combine, *or* sort out problems with profiles (or go back
to `glmmTMB`/`brms`/etc. ...)

```{r profcis,warning=FALSE}
profci <- confint(pp,parm="beta_") ## only available with devel/lme4
waldci <- confint(best_model,method="Wald",parm="beta_")
```

```{r combprof,echo=FALSE}
## combine CIs via each method, in order to plot side-by-side:
tmpfun <- function(p,lab) {
    dd <- data.frame(type=lab,
                     term=rownames(profci),
                     lwr=p[,1],
                     upr=p[,2])
    dd <- dd[dd$term != "(Intercept)",]
    dd$term <- reorder(dd$term,dd$lwr)
    rownames(dd) <- NULL
    return(dd)
}
comb <- do.call(rbind,Map(tmpfun,list(profci,waldci),
                  c("profile","Wald")))
ggplot(comb,aes(x=term,ymin=lwr,ymax=upr))+
    labs(x="")+
    geom_linerange(aes(colour=type),
                   position=position_dodge(width=0.5),size=3)+
    scale_colour_brewer(palette="Dark2")+
    coord_flip()
```

Pick CI type:

```{r coeftype}
ci_method <- "Wald" ## or 'profile' or 'boot'
```

```{r best_coefplot,warning=FALSE,fig.width=8}
get_coeftab <- function(model,ci_method="Wald") {
    cc <- confint(model,method=ci_method)
    coeftab <- tidy(model) %>% filter(term !="(Intercept)")
    ## drop spurious numeric values
    tt <- gsub("\\.[0-9]","",coeftab$term)
    ## group separator -> bar
    tt <- gsub("\\.(flor_realms$|biome$|biome_FR$)","|\\1",tt)
    coeftab$term <- tt
    ## nppcv_var <- coeftab$nppcv_var <- grepl("NPP_cv",tt)
    ## re_var <- grepl("^(sd|cor)",tt)  ## & !nppcv_var
    ## otherfix_var <- !re_var & !nppcv_var
    ## fix_var <- !re_var
    ee <- coeftab$estimate
    ## order by magnitude within
    ## (1) random effects
    ## (2) fixed effects
    ## (3) NPPcv
    ## coeftab$term <- factor(tt,
    ##    levels=c((tt[re_var])[order(ee[re_var])],
    ##      (tt[fix_var])[order(ee[fix_var])]
    ##      (tt[nppcv_var])[order(ee[nppcv_var])]))
    mm <- match(tt,rownames(cc))
    mm[is.na(mm)] <- match("sigma",rownames(cc))
    coeftab$lwr <- cc[mm,"2.5 %"]
    coeftab$upr <- cc[mm,"97.5 %"]
    ## coeftab$sd_var <- grepl("^sd",coeftab$term)
    ## coeftab$nppcv_fac <- factor(coeftab$nppcv_var,
    ## labels=c("non-NPPcv terms", "NPPcv terms"))
    return(coeftab)
}
coeftabs <- bind_rows(lapply(best_models,get_coeftab),
                      .id="taxon")
## reorder parameters
mean_est <- coeftabs %>% group_by(term,effect) %>%
    summarise(est=mean(estimate))
fix_var <- mean_est$effect=="fixed"
flevs <- with(mean_est,
              c((term[!fix_var])[order(est[!fix_var])],
                (term[fix_var] )[order(est[fix_var])]))
coeftabs$term <- factor(coeftabs$term,levels=flevs)
```

```{r coeftab_plot,fig.height=7,fig.width=7}
ggplot(coeftabs,aes(estimate,term,
                     colour=effect))+
    scale_colour_manual(values=c("black","red"),guide=FALSE)+
    geom_point()+
    geom_errorbarh(aes(xmin=lwr, # estimate-1.96*std.error,
                       xmax=upr, # estimate+1.96*std.error
                       ),height=0)+
    geom_vline(xintercept=0,lty=2)+
    facet_wrap(~taxon)+  ## ncol=1 might be nice, but too skinny
    labs(x="",y="")
```

```{r plotfun,echo=FALSE}
plotfun <- function(model=best_model,
                    xvar="NPP_log",
                    auxvar="Feat_cv_sc",
                    respvar=NULL,
                    aux_quantiles=c(0.1,0.5,0.9),
                    pred_lower_lim= -3,
                    data = ecoreg,
                    re.form = NA  ## exclude REs from prediction
                    ) {
    ## get LHS of formula
    mrespvar <- deparse(formula(best_model)[[2]])
    if (is.null(respvar)) respvar <- mrespvar
    ## extract variables from data set by name
    xx <- data[[xvar]]
    aa <- drop(data[[auxvar]])
    ## add factor equiv of auxvar to data
    av <- all.vars(formula(model,fixed.only=TRUE))
    othervars <- setdiff(av,c(respvar,xvar,auxvar,mrespvar))
    ## construct prediction frame
    pdata <- expand.grid(seq(min(xx),max(xx),length=51),
                         quantile(aa,aux_quantiles))
    names(pdata) <- c(xvar,auxvar)
    ## variables other than primary x-variable and aux are set to median
    ##  (more consistent to set to mean=0)?
    for (i in othervars) {
        pdata[[i]] <- median(data[[i]])
    }
    fauxvar <- paste0("f",auxvar)
    pdata[[fauxvar]] <- factor(pdata[[auxvar]],labels=paste0("(",aux_quantiles,")"))
    pdata[[focal]] <- predict(best_model,newdata=pdata,re.form=re.form)
    pdata[[focal]][pdata[[focal]] < pred_lower_lim] <- NA
    gg0 <- ggplot(data,aes_(x=as.name(xvar),y=as.name(respvar)))+
        ## geom_encircle(aes(group=biome_FR),expand=0)+  ## ugly ...
        ## use model respvar for predicted values
        geom_line(data=pdata,aes_(y=as.name(mrespvar),linetype=as.name(fauxvar))) +
        ## FIXME (don't hard-code line types)
        scale_linetype_manual(values=c(2,1,3))+
        ## scale_y_continuous(limits=c(-3,1),oob=scales::squish)+
        theme(legend.box="horizontal")
    return(gg0 + geom_point(aes(colour=biome,shape=flor_realms)))
}
```

`plotfun()` takes arguments:

- `model`: fitted model
- `xvar` ("NPP_log"): x-variable
- `auxvar` ("Feat_cv_sv"): auxiliary variable (e.g. for examining interactions)
- `respvar` (equal to model response by default): response variable
- `aux_quantiles`: (0.1, 0.5, 0.9) quantiles of auxiliary variable to predict
- `pred_lower_lim` (-3) : lower cut off values (log scale)
- `data` (ecoreg)
- `re.form` (NA) which RE to include in *predictions* (default is none)

```{r predplot,fig.width=10,fig.height=8,warning=FALSE}
ggplot1 <- plotfun(best_model)
print(ggplot1)
```

plot fixes: (1) confidence intervals on predictions; (2) ? relabel axes with absolute rather than log values; ?

```{r remefplot,fig.width=10,fig.height=8,warning=FALSE}
fix_NAs <- function(rem,model) {
    if (!is.null(nastuff <- attr(model.frame(model),"na.action"))) {
        return(napredict(nastuff,rem))
    } else return(rem)
}
rem1 <- fix_NAs(remef(best_model,ran="all"),best_model)
if (length(rem1)==nrow(ecoreg)) {
    ## if it worked ...
    ecoreg$rem1 <- rem1
    ## update previous plot:
    plotfun(best_model,respvar="rem1")
}
```

```{r other_plot}
ecoreg$rem2 <- fix_NAs(remef(best_model,ran="all",
                             fix=c("NPP_log","NPP_cv_sc","Feat_cv_sc"),grouping=TRUE),
                       best_model)
ecoreg$rem3 <- fix_NAs(remef(best_model,ran="all",
                             fix=c("NPP_log","NPP_cv_sc","Feat_log"),grouping=TRUE),
                       best_model)
## FIXME: drop dimensions on Feat_cv_sc upstream
gg1 <- ggplot(ecoreg,aes(c(Feat_cv_sc),rem3))+
    geom_point(aes(colour=biome,shape=flor_realms))+
    geom_smooth(group=1)+
    theme(legend.box="horizontal")
print(gg1)
```

## Rsq

```{r rsq}
plot(r2beta(best_model),maxcov=8)+scale_y_log10()+coord_flip()
```

## Models without biome/realm interaction


## To do

- more/nicer $R^2$ plots?
- fit models without biome/realm interaction
- CIs on predictions
- examine models to see when profile CIs can be used; fix profiles?

## To do (fancy)

- More on Bates et al. approach?
- Try with Julia??
- Factor-analytic approach (e.g. @plmixed)?


